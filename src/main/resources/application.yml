server:
#  port: 8080
# 随机端口
  port: ${random.int[2000,8000]}
#debug: true

logging:
  file:
    path: ./logs

################### Mybatis config ###################
mybatis:
  mapper-locations: classpath:mapping/*Mapper.xml
  type-aliases-package: com.quan.entity

################### Spring config begin ###################
spring:
  application:
    name: spring-water-application
  ################### Security config ###################
  security:
    user:
      name: root
      password: root
      roles: admin
  ################### Datasource config ###################
  datasource:
    username: root
    password: ENC(h0FuKCIDDxtJDagwvCWZPg==)
    url: jdbc:mysql://127.0.0.1:3306/cas?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&characterEncoding=utf8&useSSL=false&serverTimezone=UTC
    driver-class-name: com.mysql.cj.jdbc.Driver
  ################### Jackson config ###################
  jackson:
    date-format: yyyy-MM-dd HH:mm:ss
    time-zone: Asia/Shanghai
  ################# Redis config #################
  redis:
    host: 120.76.175.67
    port: 6379
    database: 0
    #    password: ENC(rif+QPIsBzSVxyXJWRoCohI5cQpZE+a9)
    timeout: 1000
    jedis:
      pool:
        max-active: 20
        max-idle: 10
        min-idle: 0
        max-wait: -1
  ################# kafka config #################
  kafka:
    # 指定kafka 代理地址，可以多个
    bootstrap-servers: 120.76.175.67:9092
    template:
      # 指定默认topic id
      default-topic: producer
    listener:
      # 指定listener 容器中的线程数，用于提高并发量
      missing-topics-fatal: false
      concurrency: 100
    #=============== consumer =======================
    consumer:
      # 默认消费者组
      group-id: myGroup
      client-id: 200
      # 批量一次最大拉取数据量
      max-poll-records: 80
      # 最早未被消费的offset
      # 当没有初始偏移量或当前偏移量不存在时设置消费的起始点(earliest、latest、none三个值可选择)
      auto-offset-reset: earliest
      # 是否后台自动提交偏移量
      enable-auto-commit: true
      # 后台自动提交消费偏移量(后台定时提交)的间隔时间
      auto-commit-interval: 1000
      bootstrap-servers: 120.76.175.67:9092
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        session:
          timeout:
            ms: 20000
        max:
          poll:
            interval:
              ms: 10000
    #=============== producer =======================
    producer:
      # 批量发送的消息数量
      batch-size: 16384
      # 32MB的批处理缓冲区
      buffer-memory: 33554432
      # 重试次数
      retries: 3
      client-id: 200
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 生产者要求领导者在考虑完成请求之前收到的确认数量
      acks: 1
  ################# RabbitMQ config #################
  rabbitmq:
    host: 120.76.175.67
    port: 5672
    username: guest
    password: ENC(uLi03Ellq+ON+mXDJajfcQ====)
    virtualHost: /
  ################# Flyway config #################
  flyway:
    # 是否开启flywary，默认true.
    enabled: true
    # 对执行迁移时基准版本的描述
    baseline-description: << Flyway Baseline >>
    # 当迁移时发现目标schema非空，而且带有没有元数据的表时，是否自动执行基准迁移，默认false.
    baseline-on-migrate: false
    # 开始执行基准迁移时对现有的schema的版本打标签，默认值为1.
    baseline-version: 1
    # 检查迁移脚本的位置是否存在，默认false.
    check-location: false
    # 当发现校验错误时是否自动调用clean，默认false.
    clean-on-validation-error: false
    # 设置迁移时的编码，默认UTF-8.
    encoding: UTF-8
    # 迁移脚本的位置，默认db/migration.
    locations:
      - classpath:db/migration
    # 是否允许无序的迁移，默认false.
    out-of-order: false
    # 设置每个placeholder的前缀，默认${.
    placeholder-prefix: ${
    # 设置每个placeholder的后缀，默认}.
    placeholder-suffix: "}"
    # 可重复迁移文件前缀。默认R
    repeatableSqlMigrationPrefix: R
    # 迁移文件的前缀，默认为V.
    sql-migration-prefix: V
    # 迁移脚本的文件名分隔符，默认__
    sql-migration-separator: __
    # 迁移脚本的文件名后缀
    sqlMigrationSuffixes:
      - .sql
    # 设定需要flywary迁移的schema，大小写敏感，默认为连接默认的schema.
    schemas:
      - flyway
    # 迁移时使用的目标版本，默认为latest version
    #    target: latest version
    # 迁移时使用的JDBC URL，如果没有指定的话，将使用配置的主数据源
    url: jdbc:mysql://127.0.0.1:3306/flyway?useUnicode=true&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&characterEncoding=utf8&useSSL=false&serverTimezone=UTC
    # 迁移数据库的用户名
    user: root
    # 目标数据库的密码.
    password: ENC(h0FuKCIDDxtJDagwvCWZPg==)
  ################# Spring Data config begin #################
  data:
    ################### MongoDB config ###################
    mongodb:
      host: 120.76.175.67
      port: 27017
      password: ENC(rif+QPIsBzSVxyXJWRoCohI5cQpZE+a9)
      username: admin
      database: admin
      uri: mongodb://${spring.data.mongodb.username}:${spring.data.mongodb.password}@${spring.data.mongodb.host}:${spring.data.mongodb.port}/${spring.data.mongodb.database}?maxpoolsize=10&minpoolsize=1&maxidletimems=600000&maxlifetimems=1800000

    ################### Neo4j config ###################
    neo4j:
      uri: bolt://120.76.175.67:7687
      username: neo4j
      password: ENC(WQ7khH1e17tw3wivLfCqNw==)
  ################# Spring Data config end #################

################### Spring config end ###################
jasypt:
  encryptor:
    password: jasypt
    # 加密算法设置 3.0.0 以后
    algorithm: PBEWithMD5AndDES
    iv-generator-classname: org.jasypt.iv.NoIvGenerator
